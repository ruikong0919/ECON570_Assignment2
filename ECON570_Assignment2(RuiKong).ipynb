{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07d80bc",
   "metadata": {},
   "source": [
    "## 1.Simulation a DGP where the outcome of interest depends on a randomly assigned treatment and some observed covariates.\n",
    "$y_i = a*T_i+\\beta'*x_i+e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444a24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b5e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c81b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dce4323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(a,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 \n",
    "    corr = 0.5 \n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 \n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) \n",
    "    C = allX[:,1].reshape([N,1]) \n",
    "    X = allX[:,2:] \n",
    "    \n",
    "    T = fn_randomize_treatment(N) \n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 \n",
    "    Yab = a*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "    \n",
    "def fn_ahat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    ahat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_ahat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (ahat,se_ahat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat \n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_run_experiments(a,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(a,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            ahat,se_tauhat = fn_ahat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            Yexp,T,X = fn_generate_data(a,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            ahat = res.params[0]\n",
    "            se_ahat = res.HC1_se[0]\n",
    "            \n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]    \n",
    "        lb = lb + [ahat-1.96*se_ahat]\n",
    "        ub = ub + [ahat+1.96*se_ahat]\n",
    "        \n",
    "    return (n_values,ahats,sehats,lb,ub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c58f2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 5\n",
    "p0 = 4 \n",
    "flagX = 1\n",
    "N = 1000\n",
    "Y,T,X = fn_generate_data(a,N,p,p0,corr,conf,flagX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a49c76bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>Y</th>\n",
       "      <th>T</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.152111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.366421</td>\n",
       "      <td>0.229596</td>\n",
       "      <td>0.597511</td>\n",
       "      <td>0.073841</td>\n",
       "      <td>-0.531055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.795042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.754837</td>\n",
       "      <td>-0.803859</td>\n",
       "      <td>-0.363306</td>\n",
       "      <td>0.617823</td>\n",
       "      <td>-0.638605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.068557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.798261</td>\n",
       "      <td>-0.308889</td>\n",
       "      <td>0.139340</td>\n",
       "      <td>-0.594667</td>\n",
       "      <td>0.591150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-21.920090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.571864</td>\n",
       "      <td>-1.643280</td>\n",
       "      <td>-1.696095</td>\n",
       "      <td>-1.475073</td>\n",
       "      <td>-1.123730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.226345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>0.601482</td>\n",
       "      <td>-0.525129</td>\n",
       "      <td>0.133324</td>\n",
       "      <td>-0.938598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>34.482473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.451091</td>\n",
       "      <td>0.947899</td>\n",
       "      <td>1.441273</td>\n",
       "      <td>1.529525</td>\n",
       "      <td>1.118742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-34.933583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.413369</td>\n",
       "      <td>-0.555605</td>\n",
       "      <td>-2.524938</td>\n",
       "      <td>-2.383613</td>\n",
       "      <td>-1.807064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>16.922554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.388632</td>\n",
       "      <td>1.012010</td>\n",
       "      <td>1.602400</td>\n",
       "      <td>-0.313116</td>\n",
       "      <td>1.085435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.439401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.530381</td>\n",
       "      <td>0.328302</td>\n",
       "      <td>0.878239</td>\n",
       "      <td>0.232086</td>\n",
       "      <td>-0.903160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-19.230488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.658895</td>\n",
       "      <td>-0.186273</td>\n",
       "      <td>-1.242265</td>\n",
       "      <td>-1.508568</td>\n",
       "      <td>-0.281859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          self    Y         T        X1        X2        X3        X4\n",
       "0     1.152111  0.0 -0.366421  0.229596  0.597511  0.073841 -0.531055\n",
       "1    -2.795042  0.0 -0.754837 -0.803859 -0.363306  0.617823 -0.638605\n",
       "2     7.068557  1.0  1.798261 -0.308889  0.139340 -0.594667  0.591150\n",
       "3   -21.920090  1.0 -0.571864 -1.643280 -1.696095 -1.475073 -1.123730\n",
       "4    -0.226345  1.0 -0.022996  0.601482 -0.525129  0.133324 -0.938598\n",
       "..         ...  ...       ...       ...       ...       ...       ...\n",
       "995  34.482473  1.0  2.451091  0.947899  1.441273  1.529525  1.118742\n",
       "996 -34.933583  1.0 -1.413369 -0.555605 -2.524938 -2.383613 -1.807064\n",
       "997  16.922554  1.0  1.388632  1.012010  1.602400 -0.313116  1.085435\n",
       "998  -1.439401  0.0 -1.530381  0.328302  0.878239  0.232086 -0.903160\n",
       "999 -19.230488  0.0 -0.658895 -0.186273 -1.242265 -1.508568 -0.281859\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate([Y,T,X],axis = 1)\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['self','Y', 'T', 'X1', 'X2','X3','X4']\n",
    "data.to_csv('Data_1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e337d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83830d",
   "metadata": {},
   "source": [
    "a. Do not control for any covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6df45319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 2517.09it/s]\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:04<00:00, 232.63it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(a,N,5,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        ahat,se_ahat = fn_ahat_means(Yt,Yc)\n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]\n",
    "    estDict[N] = {\n",
    "        'ahat':np.array(ahats).reshape([len(ahats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "554faa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.001458850695198155, RMSE=0.20282026657485275, size=0.056\n",
      "N=1000: bias=0.0021842589844469585, RMSE=0.06399720353965423, size=0.058\n"
     ]
    }
   ],
   "source": [
    "a0 = a*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(a0,results['ahat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05750f1c",
   "metadata": {},
   "source": [
    "b. control for all the covariates that affect the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aff5c7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1226.87it/s]\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:05<00:00, 194.11it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data(a,N,5,4,corr,conf,flagX)\n",
    "        Xobs = X[:,:p0]\n",
    "        covars = np.concatenate([T,Xobs],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        ahat = res.params[0]\n",
    "        se_ahat = res.HC1_se[0]\n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'ahat':np.array(ahats).reshape([len(ahats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "589906cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.003856751018786136, RMSE=0.1504381496857265, size=0.069\n",
      "N=1000: bias=-0.001248718577984226, RMSE=0.044119057711366635, size=0.051\n"
     ]
    }
   ],
   "source": [
    "a0 = a*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(a0,results['ahat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f374541",
   "metadata": {},
   "source": [
    "Example in real-life situation:\n",
    "\n",
    "For example, we want to study the relationship between years of education and hourly wage. People's hourly wage will be influenced by years of education, but also by family background and other aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79746b",
   "metadata": {},
   "source": [
    "## 2. Simulate a DGP with a confounder\n",
    "$y_i = a*T_i+0.6*Confounder+e_i$\n",
    "$T = 0.6*Confounder+u$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbc4d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data_con(a,N,p,p0,corr,conf):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 \n",
    "    corr = 0.5 \n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) \n",
    "    C = allX[:,1].reshape([N,1]) \n",
    "    X = allX[:,2:] \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "   \n",
    "    Yab = a*T+0.6*C+err\n",
    "    Tab = T+0.6*C\n",
    "    \n",
    "    return (Yab,Tab,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cdf68b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "corr = .5\n",
    "conf=True\n",
    "p = 5\n",
    "p0 = 4 \n",
    "N = 1000\n",
    "Y,T,C =fn_generate_data_con(a,N,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba542940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.912345</td>\n",
       "      <td>1.242619</td>\n",
       "      <td>0.404366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.375852</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>1.609524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.984715</td>\n",
       "      <td>1.329635</td>\n",
       "      <td>2.216058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.485213</td>\n",
       "      <td>1.188121</td>\n",
       "      <td>0.313534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.462530</td>\n",
       "      <td>0.115292</td>\n",
       "      <td>-1.474513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.231681</td>\n",
       "      <td>0.030666</td>\n",
       "      <td>0.051110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.527723</td>\n",
       "      <td>1.383308</td>\n",
       "      <td>0.638846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3.395199</td>\n",
       "      <td>1.720003</td>\n",
       "      <td>1.200005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2.832225</td>\n",
       "      <td>1.328302</td>\n",
       "      <td>2.213837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.534700</td>\n",
       "      <td>0.666584</td>\n",
       "      <td>-0.555694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y         T         C\n",
       "0    2.912345  1.242619  0.404366\n",
       "1    1.375852  0.965714  1.609524\n",
       "2    1.984715  1.329635  2.216058\n",
       "3    2.485213  1.188121  0.313534\n",
       "4    0.462530  0.115292 -1.474513\n",
       "..        ...       ...       ...\n",
       "995 -0.231681  0.030666  0.051110\n",
       "996  2.527723  1.383308  0.638846\n",
       "997  3.395199  1.720003  1.200005\n",
       "998  2.832225  1.328302  2.213837\n",
       "999  1.534700  0.666584 -0.555694\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate([Y,T,C],axis = 1)\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['Y', 'T', 'C']\n",
    "data.to_csv('Data2.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6249cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"C\", \"Y\")\n",
    "g.edge(\"C\",\"T\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421db3f",
   "metadata": {},
   "source": [
    "a.Fail to control for the confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5e64db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1552.29it/s]\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:04<00:00, 209.38it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,C = fn_generate_data_con(a,N,p,p0,corr,conf=False)\n",
    "        covars = np.concatenate([T],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        ahat = res.params[0]\n",
    "        se_ahat = res.HC1_se[0]\n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]\n",
    "    estDict[N] = {\n",
    "        'ahat':np.array(ahats).reshape([len(ahats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c78113c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.41295568787704634, RMSE=0.4367706130619919, size=0.878\n",
      "N=1000: bias=-0.4058435816881503, RMSE=0.4195727209885637, size=0.997\n"
     ]
    }
   ],
   "source": [
    "a0 = a*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(a0,results['ahat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062836b1",
   "metadata": {},
   "source": [
    "b. Do control for the confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3349f5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1417.93it/s]\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:05<00:00, 195.27it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,C = fn_generate_data_con(a,N,p,p0,corr,conf=True)\n",
    "        covars = np.concatenate([T],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        ahat = res.params[0]\n",
    "        se_ahat = res.HC1_se[0]\n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]\n",
    "    estDict[N] = {\n",
    "        'ahat':np.array(ahats).reshape([len(ahats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9866ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.40174098282808757, RMSE=0.4304916869506998, size=0.856\n",
      "N=1000: bias=-0.409915228337114, RMSE=0.4225263593164099, size=0.998\n"
     ]
    }
   ],
   "source": [
    "a0 = a*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(a0,results['ahat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75824645",
   "metadata": {},
   "source": [
    "Example in real-life situation:\n",
    "\n",
    "For example, states with higher minimum wages hire more workers and have higher employment rates. But the state of the job market, which can lead to higher minimum wages and higher employment rates, is a confounding variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e14024",
   "metadata": {},
   "source": [
    "## 3. Simulate a DGP with selection bias into the treatment\n",
    "$y_i = a*T_i+e_i$\n",
    "$X = 0.6*Y+0.6*T+u$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ee40238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data_bias(a,N,p,p0,corr,conf):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+1 #1 bias\n",
    "    corr = 0.5 \n",
    "\n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) \n",
    "    C = allX[:,1].reshape([N,1]) \n",
    "    X = allX[:,2:] \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    Y = a*T+err\n",
    "    X = 0.6*T+0.6*Y\n",
    "\n",
    "    \n",
    "    return (Y,T,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b02f9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "corr = .5\n",
    "conf=True\n",
    "p = 5\n",
    "p0 = 4 \n",
    "N = 1000\n",
    "Y,T,X = fn_generate_data_bias(a,N,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f00144c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>T</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.886010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.931606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.406508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.243905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.279467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.367680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.446513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.867908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.336569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.401942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.720041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.232025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.891262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.134757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.201895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.026521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y    T         X\n",
       "0    3.886010  1.0  2.931606\n",
       "1   -0.406508  0.0 -0.243905\n",
       "2    1.279467  1.0  1.367680\n",
       "3   -1.446513  0.0 -0.867908\n",
       "4    0.071003  0.0  0.042602\n",
       "..        ...  ...       ...\n",
       "995  2.336569  0.0  1.401942\n",
       "996  2.720041  1.0  2.232025\n",
       "997  0.891262  1.0  1.134757\n",
       "998  0.201895  0.0  0.121137\n",
       "999  0.026521  0.0  0.015913\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate([Y,T,X],axis = 1)\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['Y', 'T', 'X']\n",
    "data.to_csv('Data3.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"X\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.node(\"X\", \"X\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b9769",
   "metadata": {},
   "source": [
    "a. Control for the variable in between the path from cause to effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0aaea2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 2271.82it/s]\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:04<00:00, 232.34it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T,X = fn_generate_data_bias(a,N,p,p0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        ahat,se_ahat = fn_ahat_means(Yt,Yc)\n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]\n",
    "    estDict[N] = {\n",
    "        'ahat':np.array(ahats).reshape([len(ahats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ffa68e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.004628638075049398, RMSE=0.2056716688581379, size=0.056\n",
      "N=1000: bias=-0.004400156693251745, RMSE=0.06353894142357944, size=0.049\n"
     ]
    }
   ],
   "source": [
    "a0 = a*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(a0,results['ahat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c410200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1462.29it/s]\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:05<00:00, 195.80it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data_bias(a,N,p,p0,corr,conf)\n",
    "        Xobs = X[:,:p0]\n",
    "        covars = np.concatenate([T,Xobs],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        ahat = res.params[0]\n",
    "        se_ahat = res.HC1_se[0]\n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'ahat':np.array(ahats).reshape([len(ahats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a538d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-3.0, RMSE=3.0, size=1.0\n",
      "N=1000: bias=-3.0, RMSE=3.0, size=1.0\n"
     ]
    }
   ],
   "source": [
    "a0 = a*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(a0,results['ahat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ff56b",
   "metadata": {},
   "source": [
    "Example in real-life situation:\n",
    "\n",
    "For example, age has a direct impact on job satisfaction, but at the same time age affects income, and income affects job satisfaction. Here, X is income, T is age, and Y is job satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796ad4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
